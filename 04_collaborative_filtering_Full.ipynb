{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "import sys\n",
    "import traceback\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "import time\n",
    "from copy import deepcopy\n",
    "\n",
    "from sklearn.base import BaseEstimator\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.model_selection import GridSearchCV\n",
    "from sklearn.metrics import r2_score\n",
    "from sklearn.metrics import mean_squared_error\n",
    "from sklearn.metrics import accuracy_score\n",
    "from sklearn.metrics import confusion_matrix\n",
    "\n",
    "from scipy import sparse\n",
    "\n",
    "import pickle\n",
    "\n",
    "from IPython.display import display, HTML, Markdown\n",
    "\n",
    "import matplotlib\n",
    "import matplotlib.pyplot as plt\n",
    "\n",
    "import seaborn as sns\n",
    "pd.set_option('display.width', 15000)\n",
    "pd.set_option('display.max_columns', 100)\n",
    "sns.set_style(\"whitegrid\", {'axes.grid' : False})\n",
    "sns.set_context('poster')\n",
    "%matplotlib inline\n",
    "\n",
    "from surprise import Dataset, Reader\n",
    "from surprise import NormalPredictor, BaselineOnly, SVD, SVDpp, NMF, \\\n",
    "SlopeOne, CoClustering, KNNBasic, KNNWithMeans, KNNBaseline\n",
    "\n",
    "from recommender import plot_cm, get_results, show_results, IO, show_summaries\n",
    "from recommender import ModeClassifier, BaselineMean, BaselineRegression, ALS1, ALS2, RS_surprise"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "city = 'Full'\n",
    "fig_dir = 'figs/modeling/{}/'.format(city)\n",
    "data_dir = 'data/{}/'.format(city)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Wall time: 8.5 s\n"
     ]
    }
   ],
   "source": [
    "%%time\n",
    "# Load data\n",
    "\n",
    "dfb = pd.read_pickle(data_dir + 'business.pkl')\n",
    "dfr = pd.read_pickle(data_dir + 'review.pkl')\n",
    "dfu = pd.read_pickle(data_dir + 'user.pkl')\n",
    "datar = pd.read_pickle(data_dir + 'data_review.pkl')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Total number of reviews: 4166778.\n",
      "Number of restaurants: 131025.\n",
      "Number of users: 1117891.\n"
     ]
    }
   ],
   "source": [
    "sizes = [datar.shape[0], dfb.shape[0], dfu.shape[0]]\n",
    "print('Total number of reviews: {}.'.format(datar.shape[0]))\n",
    "print('Number of restaurants: {}.'.format(dfb.shape[0]))\n",
    "print('Number of users: {}.'.format(dfu.shape[0]))\n",
    "\n",
    "del dfb\n",
    "del dfu\n",
    "del dfr\n",
    "\n",
    "IO(data_dir + 'sizes.pkl').to_pickle(sizes)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "# Split the dataset into a training set a test set\n",
    "\n",
    "X_train, X_test, y_train, y_test = train_test_split(datar[['user_id', 'business_id']].values, datar['stars'].values, \\\n",
    "                                                   test_size=0.4, random_state=0)\n",
    "X_cv, X_test, y_cv, y_test = train_test_split(X_test, y_test, test_size=0.6, random_state=0)\n",
    "\n",
    "data_split = [X_train, y_train, X_test, y_test, X_cv, y_cv]\n",
    "\n",
    "IO(data_dir + 'data_split.pkl').to_pickle(data_split)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "models = [ModeClassifier(), RS_surprise(NormalPredictor()), BaselineMean(), BaselineRegression(), \\\n",
    "          RS_surprise(BaselineOnly()), RS_surprise(KNNBasic()), RS_surprise(KNNWithMeans()), RS_surprise(KNNBaseline()), \\\n",
    "          ALS1(), ALS2(), RS_surprise(SVD()), RS_surprise(SVDpp()), RS_surprise(NMF()), RS_surprise(SlopeOne()), \\\n",
    "          RS_surprise(CoClustering())]\n",
    "model_names = ['Mode estimator', 'Normal predictor*', 'Baseline (mean)', 'Baseline (regression)', \\\n",
    "              'Baseline (ALS)*', 'KNN (basic)*', 'KNN (with means)*', 'KNN (baseline)*', \\\n",
    "              'SVD-ALS1', 'SVD-ALS2', 'SVD-SGD*', 'SVD++-SGD*', 'NMF-SGD*', 'Slope one*', 'Co-clustering*']\n",
    "test = [True, True, True, True, \\\n",
    "       True, False, False, False, \\\n",
    "       True, True, True, True, True, False, False]\n",
    "fignames = [fig_dir + str(i) + 'cm.png' for i in range(len(models))]\n",
    "datanames = [data_dir + 'results/' + str(i) + '.pkl' for i in range(len(models))]\n",
    "\n",
    "IO(data_dir + 'results/models.pkl').to_pickle(models)\n",
    "IO(data_dir + 'results/model_names.pkl').to_pickle(model_names)\n",
    "IO(data_dir + 'results/fignames.pkl').to_pickle(fignames)\n",
    "IO(data_dir + 'results/datanames.pkl').to_pickle(datanames)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Mode estimator...\n",
      "Mode estimator fitting successful.\n",
      "Mode estimator cv r2 calculation successful.\n",
      "Saving to pickle successful.\n",
      "\n",
      "Normal predictor*...\n",
      "Normal predictor* fitting successful.\n",
      "Normal predictor* cv r2 calculation successful.\n",
      "Saving to pickle successful.\n",
      "\n",
      "Baseline (mean)...\n",
      "Baseline (mean) fitting successful.\n",
      "Baseline (mean) cv r2 calculation successful.\n",
      "Saving to pickle successful.\n",
      "\n",
      "Baseline (regression)...\n",
      "Baseline (regression) fitting successful.\n",
      "Baseline (regression) cv r2 calculation successful.\n",
      "Saving to pickle successful.\n",
      "\n",
      "Baseline (ALS)*...\n",
      "Estimating biases using als...\n",
      "Baseline (ALS)* fitting successful.\n",
      "Baseline (ALS)* cv r2 calculation successful.\n",
      "Saving to pickle successful.\n",
      "\n",
      "KNN (basic)*...\n",
      "Estimator not tested\n",
      "\n",
      "KNN (with means)*...\n",
      "Estimator not tested\n",
      "\n",
      "KNN (baseline)*...\n",
      "Estimator not tested\n",
      "\n",
      "SVD-ALS1...\n",
      "SVD-ALS1 fitting successful.\n",
      "SVD-ALS1 cv r2 calculation successful.\n",
      "Saving to pickle successful.\n",
      "\n",
      "SVD-ALS2...\n"
     ]
    }
   ],
   "source": [
    "%%time\n",
    "\n",
    "is_successful = []\n",
    "\n",
    "for i, model in enumerate(models):\n",
    "    try:\n",
    "        print(model_names[i] + '...')\n",
    "        if not test[i]:\n",
    "            print('Estimator not tested')\n",
    "            is_successful.append(False)\n",
    "            print()\n",
    "            continue\n",
    "        model.fit(X_train, y_train)\n",
    "        print(model_names[i] + ' fitting successful.')\n",
    "        model.cv_r2 = model.score(X_cv, y_cv, scoring='r2')\n",
    "        print(model_names[i] + ' cv r2 calculation successful.')\n",
    "        try:\n",
    "            IO(datanames[i]).to_pickle(model)\n",
    "            print('Saving to pickle successful.')\n",
    "        except:\n",
    "            traceback.print_exc()\n",
    "            print('Saving to pickle failed.')\n",
    "        del model\n",
    "        is_successful.append(True)\n",
    "        print()\n",
    "    except:\n",
    "        traceback.print_exc()\n",
    "        print(model_names[i] + ' failed.')\n",
    "        is_successful.append(False)\n",
    "        print()\n",
    "\n",
    "IO(data_dir + 'results/is_successful.pkl').to_pickle(is_successful)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "%%time\n",
    "\n",
    "is_successful = IO(data_dir + 'results/is_successful.pkl').read_pickle()\n",
    "datanames = IO(data_dir + 'results/datanames.pkl').read_pickle()\n",
    "model_names = IO(data_dir + 'results/model_names.pkl').read_pickle()\n",
    "fignames = IO(data_dir + 'results/fignames.pkl').read_pickle()\n",
    "X_train, y_train, X_test, y_test, X_cv, y_cv = IO(data_dir + 'data_split.pkl').read_pickle()\n",
    "\n",
    "results = []\n",
    "for i in range(len(is_successful)):\n",
    "    print(model_names[i] + '...')\n",
    "    if not is_successful[i]:\n",
    "        results.append(None)\n",
    "    else:\n",
    "        model = IO(datanames[i]).read_pickle()\n",
    "        results.append(get_results(model, X_train=X_train, y_train=y_train, X_test=X_test, y_test=y_test, \\\n",
    "                                   X_cv=X_cv, y_cv=y_cv))\n",
    "        del model\n",
    "        \n",
    "print('Done.')\n",
    "IO(data_dir + 'results/results.pkl').to_pickle(results)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "%%time\n",
    "\n",
    "model_names = IO(data_dir + 'results/model_names.pkl').read_pickle()\n",
    "results = IO(data_dir + 'results/results.pkl').read_pickle()\n",
    "is_successful = IO(data_dir + 'results/is_successful.pkl').read_pickle()\n",
    "sizes = IO(data_dir + 'sizes.pkl').read_pickle()\n",
    "\n",
    "display(Markdown('## {} <sup>({} reviews, {} restaurants, {} users)</sup>'.\\\n",
    "                 format(city, sizes[0], sizes[1], sizes[2])))\n",
    "display(Markdown('**Collaborative filtering**'))\n",
    "show_summaries(model_names, results, is_successful)\n",
    "display(Markdown('<sup>(* shows the algorithms we implemented by wrapping around \\\n",
    "methods in scikit-surprise python package)</sup>'))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": false
   },
   "outputs": [],
   "source": [
    "%%time\n",
    "\n",
    "is_successful = IO(data_dir + 'results/is_successful.pkl').read_pickle()\n",
    "datanames = IO(data_dir + 'results/datanames.pkl').read_pickle()\n",
    "model_names = IO(data_dir + 'results/model_names.pkl').read_pickle()\n",
    "fignames = IO(data_dir + 'results/fignames.pkl').read_pickle()\n",
    "results = IO(data_dir + 'results/results.pkl').read_pickle()\n",
    "X_train, y_train, X_test, y_test, X_cv, y_cv = IO(data_dir + 'data_split.pkl').read_pickle()\n",
    "\n",
    "for i in range(len(is_successful)):\n",
    "    if is_successful[i]:\n",
    "        model = IO(datanames[i]).read_pickle()\n",
    "        show_results(model, model_names[i], X_train=X_train, y_train=y_train, X_test=X_test, y_test=y_test, \\\n",
    "                     results=results[i], show_cv=True)\n",
    "        del model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
