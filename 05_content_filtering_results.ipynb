{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "import sys\n",
    "import traceback\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "import time\n",
    "from copy import deepcopy\n",
    "\n",
    "from sklearn.base import BaseEstimator\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.model_selection import GridSearchCV\n",
    "from sklearn.metrics import r2_score\n",
    "from sklearn.metrics import mean_squared_error\n",
    "from sklearn.metrics import accuracy_score\n",
    "from sklearn.metrics import confusion_matrix\n",
    "\n",
    "from sklearn.preprocessing import StandardScaler\n",
    "from sklearn.linear_model import Ridge, RidgeCV, LogisticRegression, LogisticRegressionCV\n",
    "\n",
    "from scipy import sparse\n",
    "\n",
    "import pickle\n",
    "\n",
    "from IPython.display import display, HTML, Markdown\n",
    "\n",
    "import matplotlib\n",
    "import matplotlib.pyplot as plt\n",
    "\n",
    "import seaborn as sns\n",
    "pd.set_option('display.width', 15000)\n",
    "pd.set_option('display.max_columns', 100)\n",
    "sns.set_style(\"whitegrid\", {'axes.grid' : False})\n",
    "sns.set_context('poster')\n",
    "%matplotlib inline\n",
    "\n",
    "from surprise import Dataset, Reader\n",
    "from surprise import NormalPredictor, BaselineOnly, SVD, SVDpp, NMF, \\\n",
    "SlopeOne, CoClustering, KNNBasic, KNNWithMeans, KNNBaseline\n",
    "\n",
    "from recommender import plot_cm, get_results, show_results, IO, show_summaries, get_X\n",
    "from recommender import ModeClassifier, BaselineMean, BaselineRegression, ALS1, ALS2, RS_surprise, RS_sklearn"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Champaign...\n",
      "Champaign preprocessing successful.\n",
      "\n",
      "Cleveland...\n",
      "Cleveland preprocessing successful.\n",
      "\n",
      "Pittsburgh...\n",
      "Pittsburgh preprocessing successful.\n",
      "\n",
      "Toronto...\n",
      "Toronto preprocessing successful.\n",
      "\n",
      "Las_Vegas...\n",
      "Las_Vegas preprocessing successful.\n",
      "\n",
      "Full...\n",
      "Full preprocessing successful.\n",
      "\n",
      "Wall time: 4min 26s\n"
     ]
    }
   ],
   "source": [
    "%%time\n",
    "\n",
    "cities = ['Champaign', 'Cleveland', 'Pittsburgh', 'Toronto', 'Las_Vegas', 'Full']\n",
    "\n",
    "for city in cities:\n",
    "    print(city + '...')\n",
    "    fig_dir = 'figs/modeling/{}/'.format(city)\n",
    "    data_dir = 'data/{}/'.format(city)\n",
    "\n",
    "    dfb = pd.read_pickle(data_dir + 'business.pkl')\n",
    "    dfu = pd.read_pickle(data_dir + 'user.pkl')\n",
    "\n",
    "    X_train, y_train, X_test, y_test, X_cv, y_cv = IO(data_dir + 'data_split.pkl').read_pickle()\n",
    "\n",
    "    X_train = get_X(X_train, dfb, dfu)\n",
    "    X_test = get_X(X_test, dfb, dfu)\n",
    "    X_cv = get_X(X_cv, dfb, dfu)\n",
    "\n",
    "    data_split = [X_train, y_train, X_test, y_test, X_cv, y_cv]\n",
    "\n",
    "    IO(data_dir + '05_data_split.pkl').to_pickle(data_split)\n",
    "\n",
    "    del dfb\n",
    "    del dfu\n",
    "    del data_split\n",
    "    print(city + ' preprocessing successful.')\n",
    "    print()\n",
    "    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Champaign...\n",
      "Cleveland...\n",
      "Pittsburgh...\n",
      "Toronto...\n",
      "Las_Vegas...\n",
      "Full...\n",
      "Wall time: 17 ms\n"
     ]
    }
   ],
   "source": [
    "%%time\n",
    "\n",
    "cities = ['Champaign', 'Cleveland', 'Pittsburgh', 'Toronto', 'Las_Vegas', 'Full']\n",
    "\n",
    "for city in cities:\n",
    "    print(city + '...')\n",
    "    fig_dir = 'figs/modeling/{}/'.format(city)\n",
    "    data_dir = 'data/{}/'.format(city)\n",
    "    \n",
    "    models = [RS_sklearn(RidgeCV()), RS_sklearn(LogisticRegressionCV(class_weight='balanced'))]\n",
    "    model_names = ['Ridge regression', 'Logistic regression']\n",
    "    test = [True, True]\n",
    "    datanames = [data_dir + 'results05/' + str(i) + '.pkl' for i in range(len(models))]\n",
    "\n",
    "    IO(data_dir + 'results05/models.pkl').to_pickle(models)\n",
    "    IO(data_dir + 'results05/model_names.pkl').to_pickle(model_names)\n",
    "    IO(data_dir + 'results05/datanames.pkl').to_pickle(datanames)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Champaign...\n",
      "Ridge regression...\n",
      "Ridge regression fitting successful.\n",
      "Ridge regression cv r2 calculation successful.\n",
      "Saving to pickle successful.\n",
      "\n",
      "Logistic regression...\n",
      "Logistic regression fitting successful.\n",
      "Logistic regression cv r2 calculation successful.\n",
      "Saving to pickle successful.\n",
      "\n",
      "Cleveland...\n",
      "Ridge regression...\n",
      "Ridge regression fitting successful.\n",
      "Ridge regression cv r2 calculation successful.\n",
      "Saving to pickle successful.\n",
      "\n",
      "Logistic regression...\n",
      "Logistic regression fitting successful.\n",
      "Logistic regression cv r2 calculation successful.\n",
      "Saving to pickle successful.\n",
      "\n",
      "Pittsburgh...\n",
      "Ridge regression...\n",
      "Ridge regression fitting successful.\n",
      "Ridge regression cv r2 calculation successful.\n",
      "Saving to pickle successful.\n",
      "\n",
      "Logistic regression...\n",
      "Logistic regression fitting successful.\n",
      "Logistic regression cv r2 calculation successful.\n",
      "Saving to pickle successful.\n",
      "\n",
      "Toronto...\n",
      "Ridge regression...\n",
      "Ridge regression fitting successful.\n",
      "Ridge regression cv r2 calculation successful.\n",
      "Saving to pickle successful.\n",
      "\n",
      "Logistic regression...\n",
      "Logistic regression fitting successful.\n",
      "Logistic regression cv r2 calculation successful.\n",
      "Saving to pickle successful.\n",
      "\n",
      "Las_Vegas...\n",
      "Ridge regression...\n",
      "Ridge regression fitting successful.\n",
      "Ridge regression cv r2 calculation successful.\n",
      "Saving to pickle successful.\n",
      "\n",
      "Logistic regression...\n",
      "Logistic regression fitting successful.\n",
      "Logistic regression cv r2 calculation successful.\n",
      "Saving to pickle successful.\n",
      "\n",
      "Full...\n",
      "Ridge regression...\n",
      "Ridge regression fitting successful.\n",
      "Ridge regression cv r2 calculation successful.\n",
      "Saving to pickle successful.\n",
      "\n",
      "Logistic regression...\n"
     ]
    }
   ],
   "source": [
    "%%time\n",
    "\n",
    "cities = ['Champaign', 'Cleveland', 'Pittsburgh', 'Toronto', 'Las_Vegas', 'Full']\n",
    "\n",
    "for city in cities:\n",
    "    print(city + '...')\n",
    "    fig_dir = 'figs/modeling/{}/'.format(city)\n",
    "    data_dir = 'data/{}/'.format(city)\n",
    "\n",
    "    is_successful = []\n",
    "    \n",
    "    datanames = IO(data_dir + 'results05/datanames.pkl').read_pickle()\n",
    "    models = IO(data_dir + 'results05/models.pkl').read_pickle()\n",
    "    model_names = IO(data_dir + 'results05/model_names.pkl').read_pickle()\n",
    "    X_train, y_train, X_test, y_test, X_cv, y_cv = IO(data_dir + '05_data_split.pkl').read_pickle()\n",
    "    \n",
    "    for i, model in enumerate(models):\n",
    "        try:\n",
    "            print(model_names[i] + '...')\n",
    "            if not test[i]:\n",
    "                print('Estimator not tested')\n",
    "                is_successful.append(False)\n",
    "                print()\n",
    "                continue\n",
    "            model.fit(X_train, y_train)\n",
    "            print(model_names[i] + ' fitting successful.')\n",
    "            model.cv_r2 = model.score(X_cv, y_cv, scoring='r2')\n",
    "            print(model_names[i] + ' cv r2 calculation successful.')\n",
    "            try:\n",
    "                IO(datanames[i]).to_pickle(model)\n",
    "                print('Saving to pickle successful.')\n",
    "            except:\n",
    "                traceback.print_exc()\n",
    "                print('Saving to pickle failed.')\n",
    "            del model\n",
    "            is_successful.append(True)\n",
    "            print()\n",
    "        except:\n",
    "            traceback.print_exc()\n",
    "            print(model_names[i] + ' failed.')\n",
    "            is_successful.append(False)\n",
    "            print()\n",
    "\n",
    "    IO(data_dir + 'results05/is_successful.pkl').to_pickle(is_successful)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "%%time\n",
    "\n",
    "cities = ['Champaign', 'Cleveland', 'Pittsburgh', 'Toronto', 'Las_Vegas', 'Full']\n",
    "\n",
    "for city in cities:\n",
    "    print(city + '...')\n",
    "    fig_dir = 'figs/modeling/{}/'.format(city)\n",
    "    data_dir = 'data/{}/'.format(city)\n",
    "\n",
    "    is_successful = IO(data_dir + 'results05/is_successful.pkl').read_pickle()\n",
    "    datanames = IO(data_dir + 'results05/datanames.pkl').read_pickle()\n",
    "    model_names = IO(data_dir + 'results05/model_names.pkl').read_pickle()\n",
    "    X_train, y_train, X_test, y_test, X_cv, y_cv = IO(data_dir + '05_data_split.pkl').read_pickle()\n",
    "\n",
    "    results = []\n",
    "    for i in range(len(is_successful)):\n",
    "        print(model_names[i] + '...')\n",
    "        if not is_successful[i]:\n",
    "            results.append(None)\n",
    "        else:\n",
    "            model = IO(datanames[i]).read_pickle()\n",
    "            results.append(get_results(model, X_train=X_train, y_train=y_train, X_test=X_test, y_test=y_test, \\\n",
    "                                       X_cv=X_cv, y_cv=y_cv))\n",
    "            del model\n",
    "        \n",
    "    print('Done.')\n",
    "    IO(data_dir + 'results05/results.pkl').to_pickle(results)\n",
    "    print()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "%%time\n",
    "\n",
    "cities = ['Champaign', 'Cleveland', 'Pittsburgh', 'Toronto', 'Las_Vegas', 'Full']\n",
    "\n",
    "for city in cities:\n",
    "    print(city + '...')\n",
    "    fig_dir = 'figs/modeling/{}/'.format(city)\n",
    "    data_dir = 'data/{}/'.format(city)\n",
    "    model_names = IO(data_dir + 'results05/model_names.pkl').read_pickle()\n",
    "    results = IO(data_dir + 'results05/results.pkl').read_pickle()\n",
    "    is_successful = IO(data_dir + 'results05/is_successful.pkl').read_pickle()\n",
    "    sizes = IO(data_dir + 'sizes.pkl').read_pickle()\n",
    "\n",
    "    display(Markdown('## {} <sup>({} reviews, {} restaurants, {} users)</sup>'.\\\n",
    "                     format(city, sizes[0], sizes[1], sizes[2])))\n",
    "    display(Markdown('**Content filtering**'))\n",
    "    show_summaries(model_names, results, is_successful)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": false
   },
   "outputs": [],
   "source": [
    "%%time\n",
    "\n",
    "cities = ['Champaign', 'Cleveland', 'Pittsburgh', 'Toronto', 'Las_Vegas', 'Full']\n",
    "\n",
    "for city in cities:\n",
    "    display(Markdown('## ' + city))\n",
    "    fig_dir = 'figs/modeling/{}/'.format(city)\n",
    "    data_dir = 'data/{}/'.format(city)\n",
    "\n",
    "    is_successful = IO(data_dir + 'results05/is_successful.pkl').read_pickle()\n",
    "    datanames = IO(data_dir + 'results05/datanames.pkl').read_pickle()\n",
    "    model_names = IO(data_dir + 'results05/model_names.pkl').read_pickle()\n",
    "    results = IO(data_dir + 'results05/results.pkl').read_pickle()\n",
    "    X_train, y_train, X_test, y_test, X_cv, y_cv = IO(data_dir + '05_data_split.pkl').read_pickle()\n",
    "\n",
    "    for i in range(len(is_successful)):\n",
    "        if is_successful[i]:\n",
    "            model = IO(datanames[i]).read_pickle()\n",
    "            show_results(model, model_names[i], X_train=X_train, y_train=y_train, X_test=X_test, y_test=y_test, \\\n",
    "                         results=results[i], show_cv=True)\n",
    "            del model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
